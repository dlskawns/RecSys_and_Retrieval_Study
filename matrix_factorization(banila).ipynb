{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "matrix_factorization(banila).ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dlskawns/RecSys_and_Retrieval_Study/blob/main/matrix_factorization(banila).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "2NjjHvSeZjHO"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "guRutBWPi9YL"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "class MatrixFactorization():\n",
        "  def __init__(self, R, k, learning_rate, reg_param, epochs, verbose = False):\n",
        "    \"\"\"\n",
        "    param R: rating matrix\n",
        "    param k: latent parameter\n",
        "    param learning_rate: alpha on weight update -> 학습률 파라미터\n",
        "    param reg_param: beta on weight update -> 가중치 기울기 파라미터\n",
        "    param epochs: training epochs\n",
        "    param verbose: print status\n",
        "    \"\"\"\n",
        "\n",
        "    self._R = R\n",
        "    self._k = k\n",
        "    self._learning_rate = learning_rate\n",
        "    self._reg_param = reg_param\n",
        "    self._epochs = epochs\n",
        "    self._verbose = verbose\n",
        "\n",
        "  def fit(self):\n",
        "    \"\"\"\n",
        "    training Matrix Factorization : Update matrix latent weight and bias\n",
        "    매트릭스의 잠재 가중치 및 편향을 학습하는 함수\n",
        "    self._b에 대한 설명\n",
        "    - global bias: input R에서 평가가 매겨진 rating의 평균값을 global bias로 사용 -> 매트릭스 전체의 편향을 평균으로 내는 방법\n",
        "    - 정규화 기능. 최종 rating에 음수가 들어가는 것 대신 latent feature에 음수가 포함되도록 해줌.\n",
        "    return: training_process\n",
        "    \"\"\"\n",
        "    self._num_users = self._R.shape[0]\n",
        "    self._num_items = self._R.shape[1]\n",
        "    # init latent features  # 잠재벡터 가중치 초기화 설정\n",
        "    self._P = np.random.normal(size = (self._num_users, self._k))\n",
        "    self._Q = np.random.normal(size = (self._num_items, self._k))\n",
        "    \n",
        "    # init biases # 잠재벡터 바이어스 초기화 설정\n",
        "    self._b_P = np.zeros(self._num_users)  # 유저 수 차원의 영벡터 생성\n",
        "    self._b_Q = np.zeros(self._num_items)  # 아이템 수 차원의 영벡터 생성\n",
        "    self._b = np.mean(self._R[np.where(self._R != 0)]) \n",
        "\n",
        "    # train while epochs\n",
        "    self._training_process = []           # training 현황 리스트 생성\n",
        "    for epoch in range(self._epochs):     # epoch 수 만큼 반복\n",
        "\n",
        "      # rating이 존재하는 index 기준으로 training 진행\n",
        "      for i in range(self._num_users):    # i 는 순차적으로 users 의미\n",
        "        for j in range(self._num_items):  # j 는 user i에 대해 순차적으로 items 의미\n",
        "          if self._R[i, j] > 0:           # 해당 유저 i에 대한 item j가 0이상-> 평가가 되었다면,\n",
        "            self.gradient_descent(i, j, self._R[i, j])  # gradient_descent 함수로 i와 j에 대한 경사하강을 진행\n",
        "      cost = self.cost()                  # cost 함수를 사용하며 결과값을 각 epoch 별로 변수에 저장\n",
        "      self._training_process.append((epoch, cost))  # training 현황 리스트에 epoch과 cost를 튜플 형태로 저장\n",
        "\n",
        "      # print status 프린트 할때 경과 지켜보기\n",
        "      if self._verbose == True and ((epoch + 1) % 10 == 0):   \n",
        "        print('iteration: %d ; cost = %.4f' % (epoch + 1, cost))\n",
        "\n",
        "  def cost(self):\n",
        "    \"\"\"\n",
        "    비용함수로써 RMSE를 기준으로 하여 로스를 계산하는 함수\n",
        "    return rmse cost\n",
        "    \"\"\"\n",
        "    # xi, yi: R[xi, yi]는 nonzero인 value를 의미\n",
        "    xi, yi = self._R.nonzero()  # 기존 점수행렬의 0이 아닌 index의 열벡터를 가져간다.\n",
        "    predicted = self.get_complete_matrix()  # get_complete_matrix 함수를 사용해 predicted 변수에 넣는다.\n",
        "    cost = 0  # cost 초기화\n",
        "    for x, y in zip(xi, yi):  # 0이 아닌 (유저, 아이템) index들을 각각 x, y로 가져간다.\n",
        "      cost += pow(self._R[x, y ] - predicted[x,y], 2) # 실제 행렬중 0이 아닌 index와 이것을 예측한 행렬의 점수의 차이를 구한 뒤, 제곱하여 cost에 더해준다.\n",
        "    return np.sqrt((cost) / len(xi)) #RMSE 이므로 위 cost들의 합의 평균(MSE)에 루트를 씌워주어 cost 계산을 완료한다.\n",
        "\n",
        "\n",
        "  def gradient(self, error, i, j):\n",
        "    \"\"\"\n",
        "    gradient of latent feature for GD -> 잠재요인의 경사하강을 위한 기울기 파악함수(미분)\n",
        "\n",
        "    param error: raing - prediction error\n",
        "    param i: user index\n",
        "    param j: item index\n",
        "    return: gradient of latent feature tuple\n",
        "    \"\"\"\n",
        "\n",
        "    dp = (error * self._Q[j, :]) - (self._reg_param * self._P[i, :])\n",
        "    dq = (error * self._P[i, :]) - (self._reg_param * self._Q[j, :])\n",
        "    return dp, dq\n",
        "\n",
        "  def gradient_descent(self, i, j, rating):\n",
        "    \"\"\"\n",
        "    경사하강 함수\n",
        "\n",
        "    i: user index of matrix\n",
        "    j: item index of matrix\n",
        "    rating: rating of (i,j)\n",
        "    \"\"\"\n",
        "    # get error\n",
        "    prediction = self.get_prediction(i,j)\n",
        "    error = rating - prediction\n",
        "\n",
        "    # update biases 오차에서 바이어스를 제한 값을 학습률만큼 곱해준 뒤 이전 바이어스에 더해준다.\n",
        "    self._b_P[i] += self._learning_rate *(error - self._reg_param *self._b_P[i])  \n",
        "    self._b_Q[j] += self._learning_rate *(error- self._reg_param *self._b_Q[j])\n",
        "\n",
        "    # update latent feature\n",
        "    dp, dq = self.gradient(error, i, j)\n",
        "    self._P[i, :] += self._learning_rate * dp # 미분된 가중치 기울기를 학습률과 곱해준 뒤 더해준다.\n",
        "    self._Q[j, :] += self._learning_rate * dq\n",
        "\n",
        "  def get_prediction(self, i, j):\n",
        "    \"\"\"\n",
        "    get predicted rating: user_i, item_j\n",
        "    return prediction of r_ij\n",
        "    \"\"\"\n",
        "    return self._b +self._b_P[i] + self._b_Q[j] + self._P[i, :].dot(self._Q[j, :].T)\n",
        "\n",
        "  def get_complete_matrix(self):\n",
        "    \"\"\"\n",
        "    PXQ 매트릭스를 만들고, P.bias와 Q.bais, global bias를 더해준다.\n",
        "    - PXQ 행렬에 b_P[:, np.newaxis]를 더하는 것은 각 열마다 bias를 더해주는 것 # np.newaxis는 한차원 추가되는것\n",
        "    - b_Q[np.newaxis\",]를 더하는 것은 각 행마다 bias를 더해주는 것\n",
        "    - b를 더하는 것은 element마다 bias를 더해주는 것\n",
        "    return: complete matrix R^\n",
        "    \"\"\"\n",
        "    return self._b +self._b_P[:, np.newaxis] +self._b_Q[np.newaxis,] + self._P.dot(self._Q.T)\n",
        "  \n",
        "  def print_result(self):\n",
        "    \"\"\"\n",
        "    print fit result\n",
        "    \"\"\"\n",
        "\n",
        "    print(\"User Latent P\")\n",
        "    print(self._P)\n",
        "    print(\"Item Latent Q\")\n",
        "    print(self._Q.T)\n",
        "    print(\"P x Q\")\n",
        "    print(self._P.dot(self._Q.T))\n",
        "    print('bias')\n",
        "    print(self._b)\n",
        "    print('User Latent bias')\n",
        "    print(self._b_P)\n",
        "    print('Item Latent bias')\n",
        "    print(self._b_Q)\n",
        "    print('Final R Matrix')\n",
        "    print(self.get_complete_matrix())\n",
        "    print('Final RMSE')\n",
        "    print(self._training_process[self._epochs-1][1])\n",
        "\n",
        "  def recsys(self, user_id):\n",
        "    \"\"\"\n",
        "    선택 유저(user_id)가 안본 상품 중 가장 높은 스코어로 파악되는 것 추천하는 함수\n",
        "    \"\"\"\n",
        "    completed_matrix = self.get_complete_matrix()\n",
        "    non_arr = np.where(self._R[user_id]==0)[0]\n",
        "    print(non_arr)\n",
        "    recommend_lst = completed_matrix[user_id][non_arr].argsort()[-5:]\n",
        "    return recommend_lst\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# rating matrix - User X Item : (10 X 10)\n",
        "R = np.array([\n",
        "        [1, 0, 0, 1, 3],\n",
        "        [2, 0, 3, 1, 1],\n",
        "        [1, 2, 0, 5, 0],\n",
        "        [1, 0, 0, 4, 4],\n",
        "        [2, 1, 5, 4, 0],\n",
        "        [5, 1, 5, 4, 0],\n",
        "        [0, 0, 0, 1, 0]])\n"
      ],
      "metadata": {
        "id": "Zw-UsaqObVFb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 임의의 난수 생성 -> 10명의 유저 20개의 아이템 \n",
        "np.random_seed = 24\n",
        "user_rating = np.random.randint(0, 6, size = (10,120))"
      ],
      "metadata": {
        "id": "Tv-CbSoO7aDA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "user_rating"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CV11DQnc7gxy",
        "outputId": "f186564e-e7f2-41d8-a0cb-28dadad1e74b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[3, 2, 2, ..., 3, 1, 5],\n",
              "       [1, 4, 3, ..., 0, 1, 1],\n",
              "       [5, 3, 1, ..., 0, 5, 2],\n",
              "       ...,\n",
              "       [0, 0, 3, ..., 1, 5, 4],\n",
              "       [2, 4, 3, ..., 4, 0, 3],\n",
              "       [3, 0, 3, ..., 2, 1, 0]])"
            ]
          },
          "metadata": {},
          "execution_count": 110
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "factorizer = MatrixFactorization(user_rating, k=8, learning_rate=0.01, reg_param=0.01, epochs=250, verbose=True)"
      ],
      "metadata": {
        "id": "3Dfr2DzXbrMa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "factorizer.fit()\n",
        "factorizer.recsys(0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gEJ_imtbbseF",
        "outputId": "01913cb9-2c6d-4426-d7d4-00cc37c3c6e7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "iteration: 10 ; cost = 1.2617\n",
            "iteration: 20 ; cost = 1.2031\n",
            "iteration: 30 ; cost = 1.1371\n",
            "iteration: 40 ; cost = 1.0586\n",
            "iteration: 50 ; cost = 0.9734\n",
            "iteration: 60 ; cost = 0.8891\n",
            "iteration: 70 ; cost = 0.8108\n",
            "iteration: 80 ; cost = 0.7413\n",
            "iteration: 90 ; cost = 0.6809\n",
            "iteration: 100 ; cost = 0.6290\n",
            "iteration: 110 ; cost = 0.5839\n",
            "iteration: 120 ; cost = 0.5436\n",
            "iteration: 130 ; cost = 0.5062\n",
            "iteration: 140 ; cost = 0.4703\n",
            "iteration: 150 ; cost = 0.4356\n",
            "iteration: 160 ; cost = 0.4028\n",
            "iteration: 170 ; cost = 0.3729\n",
            "iteration: 180 ; cost = 0.3469\n",
            "iteration: 190 ; cost = 0.3251\n",
            "iteration: 200 ; cost = 0.3074\n",
            "iteration: 210 ; cost = 0.2931\n",
            "iteration: 220 ; cost = 0.2816\n",
            "iteration: 230 ; cost = 0.2723\n",
            "iteration: 240 ; cost = 0.2647\n",
            "iteration: 250 ; cost = 0.2584\n",
            "[  5   9  12  13  23  28  30  40  42  50  73  75  79  81  84  87  88  89\n",
            "  92  93  94  95  96 104 115]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([10,  8,  1, 22,  6])"
            ]
          },
          "metadata": {},
          "execution_count": 112
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "Pi-5u0dZTFsv"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}